{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Jinja2\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting MarkupSafe>=2.0 (from Jinja2)\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Installing collected packages: MarkupSafe, Jinja2\n",
      "Successfully installed Jinja2-3.1.6 MarkupSafe-3.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Jinja2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raspagem de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todos da serie A (2014 - 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coletando dados da temporada 2025...\n",
      "Temporada 2025 finalizada com 20 clubes.\n",
      "Coletando dados da temporada 2024...\n",
      "Temporada 2024 finalizada com 20 clubes.\n",
      "Coletando dados da temporada 2023...\n",
      "Temporada 2023 finalizada com 20 clubes.\n",
      "Coletando dados da temporada 2022...\n",
      "Temporada 2022 finalizada com 20 clubes.\n",
      "Coletando dados da temporada 2021...\n",
      "Temporada 2021 finalizada com 20 clubes.\n",
      "Coletando dados da temporada 2020...\n",
      "Temporada 2020 finalizada com 20 clubes.\n",
      "Coletando dados da temporada 2019...\n",
      "Temporada 2019 finalizada com 20 clubes.\n",
      "Coletando dados da temporada 2018...\n",
      "Temporada 2018 finalizada com 20 clubes.\n",
      "Coletando dados da temporada 2017...\n",
      "Temporada 2017 finalizada com 20 clubes.\n",
      "Coletando dados da temporada 2016...\n",
      "Temporada 2016 finalizada com 20 clubes.\n",
      "Coletando dados da temporada 2015...\n",
      "Temporada 2015 finalizada com 20 clubes.\n",
      "Coletando dados da temporada 2014...\n",
      "Temporada 2014 finalizada com 20 clubes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Temporadas e URLs correspondentes\n",
    "temporadas_urls = {\n",
    "    \"2025\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2024\",\n",
    "    \"2024\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2023\",\n",
    "    \"2023\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2022\",\n",
    "    \"2022\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2021\",\n",
    "    \"2021\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2020\",\n",
    "    \"2020\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2019\",\n",
    "    \"2019\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2018\",\n",
    "    \"2018\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2017\",\n",
    "    \"2017\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2016\",\n",
    "    \"2016\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2015\",\n",
    "    \"2015\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2014\",\n",
    "    \"2014\": \"https://www.transfermarkt.com.br/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1/plus/?saison_id=2013\"\n",
    "\n",
    "}\n",
    "# Setup navegador headless\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Pasta para salvar os arquivos\n",
    "pasta = \"Todos_serieA\"\n",
    "os.makedirs(pasta, exist_ok=True)\n",
    "\n",
    "\n",
    "for temporada, url in temporadas_urls.items():\n",
    "    print(f\"Coletando dados da temporada {temporada}...\")\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    table = soup.find(\"table\", class_=\"items\")\n",
    "\n",
    "    clubes_data = []\n",
    "    if table:\n",
    "        rows = table.find_all(\"tr\", class_=[\"odd\", \"even\"])\n",
    "        for row in rows:\n",
    "            cols = row.find_all(\"td\")\n",
    "            if len(cols) >= 7:\n",
    "                clube = cols[1].text.strip()\n",
    "                plantel = cols[2].text.strip()\n",
    "                idade_media = cols[3].text.strip()\n",
    "                estrangeiros = cols[4].text.strip()\n",
    "                valor_medio = cols[5].text.strip()\n",
    "                valor_total = cols[6].text.strip()\n",
    "\n",
    "                clubes_data.append({\n",
    "                    \"Clube\": clube,\n",
    "                    \"Plantel\": plantel,\n",
    "                    \"√∏ Idade\": idade_media,\n",
    "                    \"Estrangeiros\": estrangeiros,\n",
    "                    \"√∏ Valor de Mercado\": valor_medio,\n",
    "                    \"Valor de Mercado Total\": valor_total\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(clubes_data)\n",
    "    df.to_csv(os.path.join(pasta, f\"valores_{temporada}.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"Temporada {temporada} finalizada com {len(df)} clubes.\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todos juntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Arquivo 'todos_clubes_serieA.csv' criado com sucesso e coluna 'Temporada' limpa!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "pasta = \"Todos_serieA\"\n",
    "arquivos = sorted([arq for arq in os.listdir(pasta) if arq.endswith(\".csv\")])\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for arquivo in arquivos:\n",
    "    temporada = arquivo.split(\"_\")[1].split(\".\")[0]  # extrai s√≥ o ano corretamente\n",
    "    df = pd.read_csv(os.path.join(pasta, arquivo))\n",
    "    df[\"Temporada\"] = temporada.strip()  # remove espa√ßos e caracteres estranhos\n",
    "    dfs.append(df)\n",
    "\n",
    "df_final = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Se quiser, s√≥ para garantir que 'Temporada' tem apenas os anos:\n",
    "df_final[\"Temporada\"] = df_final[\"Temporada\"].str.extract(r\"(\\d{4})\")  # extrai apenas os 4 d√≠gitos do ano\n",
    "\n",
    "df_final.to_csv(\"todos_clubes_serieA.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"‚úÖ Arquivo 'todos_clubes_serieA.csv' criado com sucesso e coluna 'Temporada' limpa!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformando o arquivo xlsx em CSV \n",
    "* (O arquvio cont√©m os dados dos valores do clube + pontos por temporada que foi feito no pr√≥prio excel com a formula procv) \n",
    "* Estando na aba 'Crud' la foi feito a organiza√ß√£o dos dados para colocar na aba principal \"todos_clubes_serieA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV salvo com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "caminho_excel = r\"C:\\Users\\lLuca\\OneDrive\\Documentos\\Leo_estudos\\Faculdade\\alessio\\Previsao_DePontosBrasileirao-SerieA\\Previsao_DePontosBrasileirao-SerieA\\dados\\BASE_FINAL.xlsx\"\n",
    "\n",
    "\n",
    "df = pd.read_excel(caminho_excel, sheet_name=\"CLUBES\")\n",
    "\n",
    "\n",
    "caminho_csv = r\"C:\\Users\\lLuca\\OneDrive\\Documentos\\Leo_estudos\\Faculdade\\alessio\\Previsao_DePontosBrasileirao-SerieA\\Previsao_DePontosBrasileirao-SerieA\\dados\\todos_clubes_serieA_com_pontos.csv\"\n",
    "df.to_csv(caminho_csv, index=False)\n",
    "\n",
    "print(\"CSV salvo com sucesso!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = r\"C:\\Users\\lLuca\\OneDrive\\Documentos\\Leo_estudos\\Faculdade\\alessio\\Previsao_DePontosBrasileirao-SerieA\\Previsao_DePontosBrasileirao-SerieA\\dados\\BASE_FINAL.xlsx\"\n",
    "\n",
    "# Leitura\n",
    "df = pd.read_excel(file_path, sheet_name=\"CLUBES\")\n",
    "\n",
    "# Vari√°vel bin√°ria para rebaixamento\n",
    "df['Status_bin'] = df['Status'].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "# Separar treino e previs√£o\n",
    "df_treino = df[df['Temporada'] < 2025].copy()\n",
    "df_prev = df[df['Temporada'] == 2025].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ Top 3 Modelos por Acur√°cia M√©dia:\n",
      "\n",
      "  Modelo                                           Features  Acur√°cia M√©dia  \\\n",
      "5  Logit                             Valor de Mercado Total        0.880909   \n",
      "6     NB                             Valor de Mercado Total        0.880455   \n",
      "0  Logit  √∏ Idade, Estrangeiros, √∏ Valor de Mercado, Val...        0.877727   \n",
      "7    KNN                             Valor de Mercado Total        0.868636   \n",
      "\n",
      "   MAE M√©dio  RMSE M√©dio  \n",
      "5   0.119091    0.338784  \n",
      "6   0.119545    0.339428  \n",
      "0   0.122273    0.343826  \n",
      "7   0.131364    0.357221  \n"
     ]
    }
   ],
   "source": [
    "resultados_modelos = []\n",
    "\n",
    "for comb in combinacoes:\n",
    "    X = df_treino[comb]\n",
    "    y = df_treino['Status_bin']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    for nome_modelo, modelo in models.items():\n",
    "        accs, r2s, maes, rmses = [], [], [], []\n",
    "\n",
    "        for seed in range(50):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=seed)\n",
    "            modelo.fit(X_train, y_train)\n",
    "            y_pred = modelo.predict(X_test)\n",
    "\n",
    "            accs.append(accuracy_score(y_test, y_pred))\n",
    "            r2s.append(r2_score(y_test, y_pred))\n",
    "            maes.append(mean_absolute_error(y_test, y_pred))\n",
    "            rmses.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "        resultados_modelos.append({\n",
    "            'Features': ', '.join(comb),\n",
    "            'Modelo': nome_modelo,\n",
    "            'Acur√°cia M√©dia': np.mean(accs),\n",
    "            'MAE M√©dio': np.mean(maes),\n",
    "            'RMSE M√©dio': np.mean(rmses)\n",
    "        })\n",
    "\n",
    "# Resultados\n",
    "df_resultados = pd.DataFrame(resultados_modelos)\n",
    "top3 = df_resultados.sort_values(by='Acur√°cia M√©dia', ascending=False).head(4)\n",
    "\n",
    "print(\"üèÜ Top 3 Modelos por Acur√°cia M√©dia:\\n\")\n",
    "print(top3[['Modelo', 'Features', 'Acur√°cia M√©dia',  'MAE M√©dio', 'RMSE M√©dio']])\n",
    "\n",
    "# Extrair o Logit mesmo que ele n√£o esteja no top1\n",
    "logit_row = df_resultados[df_resultados['Modelo'] == 'Logit'].sort_values(by='Acur√°cia M√©dia', ascending=False).iloc[0]\n",
    "logit_comb = logit_row['Features'].split(', ')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tendo em vista que o modelo **Logit** apresentou a **melhor acur√°cia m√©dia (0.88)** entre os modelos avaliados, ele foi selecionado como o modelo principal para ser salvo e utilizado nas previs√µes.\n",
    "\n",
    "* √â importante destacar que, por se tratar de um modelo de classifica√ß√£o, o **Logit (Regress√£o Log√≠stica)** **n√£o utiliza o R¬≤ como m√©trica adequada** para avalia√ß√£o. O R¬≤ √© uma m√©trica de regress√£o, e sua aplica√ß√£o nesse contexto pode gerar interpreta√ß√µes incorretas. Portanto, o foco da avalia√ß√£o foi baseado principalmente na acur√°cia, no MAE e no RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo Logit e scaler salvos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "X_treino_final = df_treino[logit_comb]\n",
    "y_treino_final = df_treino['Status_bin']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_treino_scaled = scaler.fit_transform(X_treino_final)\n",
    "\n",
    "\n",
    "modelo_final = LogisticRegression(max_iter=1000)\n",
    "modelo_final.fit(X_treino_scaled, y_treino_final)\n",
    "\n",
    "# Salvar o modelo treinado\n",
    "with open('modelo_logit_status.pkl', 'wb') as f:\n",
    "    pickle.dump(modelo_final, f)\n",
    "\n",
    "\n",
    "with open('scaler_logit_status.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"‚úÖ Modelo Logit e scaler salvos com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previs√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìâ Previs√£o de Rebaixamento 2025:\n",
      "                Clube  Prob_Rebaixamento Rebaixado\n",
      "239          Mirassol           0.293692       Sim\n",
      "238         Juventude           0.292524       Sim\n",
      "237             Cear√°           0.176328       Sim\n",
      "236      Sport Recife           0.127934       Sim\n",
      "235           Vit√≥ria           0.108837       N√£o\n",
      "234         Fortaleza           0.072541       N√£o\n",
      "233        Bragantino           0.021810       N√£o\n",
      "232        Fluminense           0.017973       N√£o\n",
      "231         S√£o Paulo           0.012701       N√£o\n",
      "230          Vasco da           0.008286       N√£o\n",
      "229             Bahia           0.006441       N√£o\n",
      "228            Gr√™mio           0.006090       N√£o\n",
      "227  Atl√©tico Mineiro           0.005855       N√£o\n",
      "226          Cruzeiro           0.005428       N√£o\n",
      "225            Santos           0.005263       N√£o\n",
      "224     Internacional           0.002829       N√£o\n",
      "223       Corinthians           0.001111       N√£o\n",
      "222          Botafogo           0.000543       N√£o\n",
      "221          Flamengo           0.000005       N√£o\n",
      "220         Palmeiras           0.000002       N√£o\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "with open('modelo_logit_status.pkl', 'rb') as f:\n",
    "    modelo_logit = pickle.load(f)\n",
    "\n",
    "with open('scaler_logit_status.pkl', 'rb') as f:\n",
    "    scaler_logit = pickle.load(f)\n",
    "\n",
    "\n",
    "file_path = r\"C:\\Users\\lLuca\\OneDrive\\Documentos\\Leo_estudos\\Faculdade\\alessio\\Previsao_DePontosBrasileirao-SerieA\\Previsao_DePontosBrasileirao-SerieA\\dados\\BASE_FINAL.xlsx\"\n",
    "df = pd.read_excel(file_path, sheet_name=\"CLUBES\")\n",
    "\n",
    "\n",
    "df_prev_2025 = df[df['Temporada'] == 2025].copy()\n",
    "\n",
    "\n",
    "logit_comb = ['Valor de Mercado Total'] \n",
    "\n",
    "X_prev_2025 = df_prev_2025[logit_comb]\n",
    "X_prev_scaled = scaler_logit.transform(X_prev_2025)\n",
    "\n",
    "\n",
    "prob_rebaixamento = 1 - modelo_logit.predict_proba(X_prev_scaled)[:, 1]\n",
    "\n",
    "\n",
    "df_resultado_2025 = df_prev_2025[['Clube']].copy()\n",
    "df_resultado_2025['Prob_Rebaixamento'] = prob_rebaixamento\n",
    "df_resultado_2025['Rebaixado'] = 'N√£o'\n",
    "df_resultado_2025.loc[df_resultado_2025['Prob_Rebaixamento'].nlargest(4).index, 'Rebaixado'] = 'Sim'\n",
    "\n",
    "# resultado\n",
    "print(\"\\nüìâ Previs√£o de Rebaixamento 2025:\")\n",
    "print(df_resultado_2025.sort_values(by='Prob_Rebaixamento', ascending=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c4cfe_row0_col2, #T_c4cfe_row1_col2, #T_c4cfe_row2_col2, #T_c4cfe_row3_col2 {\n",
       "  color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c4cfe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c4cfe_level0_col0\" class=\"col_heading level0 col0\" >Clube</th>\n",
       "      <th id=\"T_c4cfe_level0_col1\" class=\"col_heading level0 col1\" >Prob_Rebaixamento</th>\n",
       "      <th id=\"T_c4cfe_level0_col2\" class=\"col_heading level0 col2\" >Rebaixado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c4cfe_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c4cfe_row0_col0\" class=\"data row0 col0\" >Mirassol</td>\n",
       "      <td id=\"T_c4cfe_row0_col1\" class=\"data row0 col1\" >29.37%</td>\n",
       "      <td id=\"T_c4cfe_row0_col2\" class=\"data row0 col2\" >Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4cfe_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c4cfe_row1_col0\" class=\"data row1 col0\" >Juventude</td>\n",
       "      <td id=\"T_c4cfe_row1_col1\" class=\"data row1 col1\" >29.25%</td>\n",
       "      <td id=\"T_c4cfe_row1_col2\" class=\"data row1 col2\" >Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4cfe_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c4cfe_row2_col0\" class=\"data row2 col0\" >Cear√°</td>\n",
       "      <td id=\"T_c4cfe_row2_col1\" class=\"data row2 col1\" >17.63%</td>\n",
       "      <td id=\"T_c4cfe_row2_col2\" class=\"data row2 col2\" >Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4cfe_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c4cfe_row3_col0\" class=\"data row3 col0\" >Sport Recife</td>\n",
       "      <td id=\"T_c4cfe_row3_col1\" class=\"data row3 col1\" >12.79%</td>\n",
       "      <td id=\"T_c4cfe_row3_col2\" class=\"data row3 col2\" >Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4cfe_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c4cfe_row4_col0\" class=\"data row4 col0\" >Vit√≥ria</td>\n",
       "      <td id=\"T_c4cfe_row4_col1\" class=\"data row4 col1\" >10.88%</td>\n",
       "      <td id=\"T_c4cfe_row4_col2\" class=\"data row4 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4cfe_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c4cfe_row5_col0\" class=\"data row5 col0\" >Fortaleza</td>\n",
       "      <td id=\"T_c4cfe_row5_col1\" class=\"data row5 col1\" >7.25%</td>\n",
       "      <td id=\"T_c4cfe_row5_col2\" class=\"data row5 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4cfe_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_c4cfe_row6_col0\" class=\"data row6 col0\" >Bragantino</td>\n",
       "      <td id=\"T_c4cfe_row6_col1\" class=\"data row6 col1\" >2.18%</td>\n",
       "      <td id=\"T_c4cfe_row6_col2\" class=\"data row6 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4cfe_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_c4cfe_row7_col0\" class=\"data row7 col0\" >Fluminense</td>\n",
       "      <td id=\"T_c4cfe_row7_col1\" class=\"data row7 col1\" >1.80%</td>\n",
       "      <td id=\"T_c4cfe_row7_col2\" class=\"data row7 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4cfe_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_c4cfe_row8_col0\" class=\"data row8 col0\" >S√£o Paulo</td>\n",
       "      <td id=\"T_c4cfe_row8_col1\" class=\"data row8 col1\" >1.27%</td>\n",
       "      <td id=\"T_c4cfe_row8_col2\" class=\"data row8 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4cfe_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_c4cfe_row9_col0\" class=\"data row9 col0\" >Vasco da</td>\n",
       "      <td id=\"T_c4cfe_row9_col1\" class=\"data row9 col1\" >0.83%</td>\n",
       "      <td id=\"T_c4cfe_row9_col2\" class=\"data row9 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4cfe_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_c4cfe_row10_col0\" class=\"data row10 col0\" >Bahia</td>\n",
       "      <td id=\"T_c4cfe_row10_col1\" class=\"data row10 col1\" >0.64%</td>\n",
       "      <td id=\"T_c4cfe_row10_col2\" class=\"data row10 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4cfe_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_c4cfe_row11_col0\" class=\"data row11 col0\" >Gr√™mio</td>\n",
       "      <td id=\"T_c4cfe_row11_col1\" class=\"data row11 col1\" >0.61%</td>\n",
       "      <td id=\"T_c4cfe_row11_col2\" class=\"data row11 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4cfe_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_c4cfe_row12_col0\" class=\"data row12 col0\" >Atl√©tico Mineiro</td>\n",
       "      <td id=\"T_c4cfe_row12_col1\" class=\"data row12 col1\" >0.59%</td>\n",
       "      <td id=\"T_c4cfe_row12_col2\" class=\"data row12 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4cfe_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_c4cfe_row13_col0\" class=\"data row13 col0\" >Cruzeiro</td>\n",
       "      <td id=\"T_c4cfe_row13_col1\" class=\"data row13 col1\" >0.54%</td>\n",
       "      <td id=\"T_c4cfe_row13_col2\" class=\"data row13 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4cfe_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_c4cfe_row14_col0\" class=\"data row14 col0\" >Santos</td>\n",
       "      <td id=\"T_c4cfe_row14_col1\" class=\"data row14 col1\" >0.53%</td>\n",
       "      <td id=\"T_c4cfe_row14_col2\" class=\"data row14 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4cfe_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_c4cfe_row15_col0\" class=\"data row15 col0\" >Internacional</td>\n",
       "      <td id=\"T_c4cfe_row15_col1\" class=\"data row15 col1\" >0.28%</td>\n",
       "      <td id=\"T_c4cfe_row15_col2\" class=\"data row15 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4cfe_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_c4cfe_row16_col0\" class=\"data row16 col0\" >Corinthians</td>\n",
       "      <td id=\"T_c4cfe_row16_col1\" class=\"data row16 col1\" >0.11%</td>\n",
       "      <td id=\"T_c4cfe_row16_col2\" class=\"data row16 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4cfe_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_c4cfe_row17_col0\" class=\"data row17 col0\" >Botafogo</td>\n",
       "      <td id=\"T_c4cfe_row17_col1\" class=\"data row17 col1\" >0.05%</td>\n",
       "      <td id=\"T_c4cfe_row17_col2\" class=\"data row17 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4cfe_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_c4cfe_row18_col0\" class=\"data row18 col0\" >Flamengo</td>\n",
       "      <td id=\"T_c4cfe_row18_col1\" class=\"data row18 col1\" >0.00%</td>\n",
       "      <td id=\"T_c4cfe_row18_col2\" class=\"data row18 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4cfe_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_c4cfe_row19_col0\" class=\"data row19 col0\" >Palmeiras</td>\n",
       "      <td id=\"T_c4cfe_row19_col1\" class=\"data row19 col1\" >0.00%</td>\n",
       "      <td id=\"T_c4cfe_row19_col2\" class=\"data row19 col2\" >N√£o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x201c7ec5350>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_resultado_2025_sorted = df_resultado_2025.sort_values(by='Prob_Rebaixamento', ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_resultado_2025_sorted.style.format({\n",
    "    'Prob_Rebaixamento': '{:.2%}'\n",
    "}).applymap(lambda x: 'color: red' if isinstance(x, str) and 'Sim' in x else '', subset=['Rebaixado'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
